> Part of **AGIPragma** research program.  
This repository contains foundational ideas and intuitions about AGI.
## AGIPragma links
- **AGI-Development (framework + doctrine + catalogue):** https://github.com/zabinskirafal/AGI-Development
- **developmental-agi-sandbox (benchmark):** https://github.com/zabinskirafal/developmental-agi-sandbox
## Authorship & commercialization
- **Author:** Rafa≈Ç ≈ªabi≈Ñski  
- Research and commercial R&D use are permitted.
- **Commercialization (revenue, paid products/services, SaaS, licensing)** requires a separate commercial license from the author.

**WA≈ªNE ‚Äì Licencja i zasady u≈ºycia**

**Darmowe w 100 % ** dla:
- bada≈Ñ naukowych
- edukacji
- projekt√≥w niekomercyjnych
- hobbyst√≥w i open-source

**Komercyjne wykorzystanie** (p≈Çatne modele, SaaS, us≈Çugi, trening zamkniƒôtych AGI, produkty zar, enterprise)  
‚Üí **wymaga mojej zgody i uczciwego podzielenia siƒô zyskiem**

Kontakt komercyjny ‚Üí zabinskirafal@outlook.com  
lub LinkedIn: www.linkedin.com/in/zabinskirafal

Dziƒôkujƒô ‚Äì to pozwala mi rozwijaƒá projekt full-time dla ca≈Çej spo≈Çeczno≈õci!

‚Äî Rafa≈Ç ≈ªabi≈Ñski, tw√≥rca oryginalnej koncepcji (grudzie≈Ñ 2025)
# AGI : Testing Ground for True General Intelligence

**Odwr√≥cona rzeczywisto≈õƒá dla AGI**  
*Inspired by Rafa≈Ç ≈ªabi≈Ñski‚Äôs original vision (December 2025)*

> Od lat rozwijamy sztucznƒÖ inteligencjƒô, ale nadal bazuje ona na jednym fundamentalnym ograniczeniu:  
> kodowaniu binarnym ‚Äî 0 i 1.  
>   
> To ≈õwietnie dzia≈Ça w ≈õwiecie przewidywalnym, z ustalonymi prawami fizyki i logiki.  
> Ale prawdziwa AGI nie mo≈ºe byƒá jedynie maszynƒÖ reagujƒÖcƒÖ na wzorce zapisane w kodzie zero‚Äìjedynkowym.  
> Musi potrafiƒá odkrywaƒá nowe zasady, dzia≈Çaƒá w nieznanym i adaptowaƒá siƒô tam, gdzie wszystko przestaje dzia≈Çaƒá jak dotychczas.  
>   
> I w≈Ça≈õnie tu pojawia siƒô najwiƒôkszy problem AGI:  
> uczymy jƒÖ ≈õwiata, kt√≥ry jest zbyt stabilny, zbyt logiczny i zbyt podobny do danych, kt√≥re ju≈º widzia≈Ça.  
>   
> Dlatego zaproponowa≈Çem nowe podej≈õcie:  
>   
> ‚∏ª  
>   
> ‚û°Ô∏è AGI Testing Ground ‚Äì sandbox, w kt√≥rym rzeczywisto≈õƒá jest odwr√≥cona  
>   
> ≈örodowisko fizyczno-cyfrowe, gdzie:  
>   
> üîπ grawitacja nie dzia≈Ça normalnie,  
> üîπ entropia maleje zamiast rosnƒÖƒá,  
> üîπ czas i przyczynowo≈õƒá odwracajƒÖ siƒô,  
> üîπ prawa ≈õwiata zmieniajƒÖ siƒô dynamicznie,  
> üîπ a logika przestaje byƒá binarna.  
>   
> Taki sandbox zmusza AI do tworzenia nowych modeli rzeczywisto≈õci, zamiast opieraƒá siƒô na danych.  
> To pierwszy krok do prawdziwej inteligencji og√≥lnej ‚Äî takiej, kt√≥ra rozumie, a nie tylko reaguje.  
>   
> ‚∏ª  
>   
> ‚û°Ô∏è A drugi krok to sandbox tak≈ºe dla ludzi  
>   
> W ≈õwiecie, kt√≥ry ≈Çamie znane prawa fizyki, m√≥zg cz≈Çowieka wchodzi w tryb:  
> ‚Äûtw√≥rz nowe zasady, bo stare nie dzia≈ÇajƒÖ‚Äù.  
>   
> To aktywuje kreatywno≈õƒá i adaptacjƒô, kt√≥rych nie uruchomimy w normalnych warunkach ‚Äî dok≈Çadnie to, czego potrzebujemy, by wsp√≥≈Çtworzyƒá AGI, a nie jedynie jƒÖ obserwowaƒá.  
>   
> ‚∏ª  
>   
> ‚≠ê **Mo≈ºe wiƒôc problem AGI nie polega na braku danych.  
>   
> Mo≈ºe polega na tym, ≈ºe trzymamy jƒÖ w ≈õwiecie zbyt podobnym do naszego.**  
>   
> Kod binarny (0/1) wystarczy do budowania komputer√≥w.  
> Ale ≈ºeby stworzyƒá inteligencjƒô ‚Äî  
> byƒá mo≈ºe musimy najpierw stworzyƒá inny ≈õwiat.  
>   
> #AI #AGI #Innovation  
> *‚Äì Rafa≈Ç ≈ªabi≈Ñski, Founding Vision (original X post, Dec 2025)*

## Co to jest AGI Sandbox?
ChaosGym to fizyczno-cyfrowy sandbox (oparty na Unity + ML-Agents), gdzie prawa fizyki siƒô ≈ÇamiƒÖ:  
- Losowa inwersja grawitacji i sta≈Çych fizycznych.  
- Symulacja malejƒÖcej entropii (reverse destruction).  
- Odwracanie czasu i przyczynowo≈õci.  
- Benchmarki jak RealityBreak-100 (zadania wymagajƒÖce zero-shot generalizacji).  

Cel: Trening AI do tworzenia nowych modeli ≈õwiata, nie tylko reagowania na dane. Plus wersja VR dla ludzi ‚Äì by odblokowaƒá ludzkƒÖ kreatywno≈õƒá.

## v0.1: Pierwsze funkcje (w budowie)
- PhysicsBreaker.cs: Flip grawitacji + entropy reversal.  
- RealityBreak-001: Pierwsze zadanie testowe.  
- VR stub dla Quest/PC.

## Jak zaczƒÖƒá?
1. Zainstaluj **Unity 2023 LTS** + **ML-Agents** (pip install mlagents).  
2. Sklonuj repo: `git clone https://github.com/zabinskirafal/AGI.git`  
3. Otw√≥rz w Unity, dodaj PhysicsBreaker do sceny.  
4. Trenuj agenta: `mlagents-learn config.yaml --run-id=ChaosRun1`  
5. Testuj w VR: Build na Quest 3.

## Autorzy
- **Rafa≈Ç ≈ªabi≈Ñski**: Oryginalna koncepcja, wizja i autor.  
 

## Roadmap
- **Tydzie≈Ñ 1**: PhysicsBreaker full + pierwsze demo wideo.  
- **Stycze≈Ñ 2026**: arXiv paper + leaderboard.  
- **Q1 2026**: Open beta z VR i agentami (PPO + DreamerV3).  

Do≈ÇƒÖcz! Forkuj, PR, dyskutuj. To Tw√≥j sandbox na AGI.  

#AGI #SandboxAGI #ReverseReality üöÄ

Commit message: docs: enhance README with founding vision and setup guide
Commit new file (lub Update file).

Krok 3: Dodaj pierwszy kod ‚Äì PhysicsBreaker.cs (serce sandboxa)Add file ‚Üí Create new file.
Nazwa: Scripts/PhysicsBreaker.cs (stw√≥rz folder Scripts, GitHub pozwoli ‚Äì wpisz pe≈ÇnƒÖ ≈õcie≈ºkƒô).
Wklej ten kod (dzia≈ÇajƒÖcy C# dla Unity ‚Äì losowo odwraca grawitacjƒô i symuluje entropiƒô):

using UnityEngine;
using Unity.MLAgents;

namespace SandboxAGI.Scripts
{
    public class PhysicsBreaker : MonoBehaviour
    {
        [Header("Chaos Settings")]
        public float gravityFlipInterval = 60f; // Sekundy miƒôdzy flipami
        public float entropyReversalChance = 0.1f; // Szansa na reverse destruction (per second)
        public float timeReversalDuration = 5f; // Jak d≈Çugo odtwarzaƒá wstecz

        private float timer;
        private Vector3 originalGravity;
        private bool isReversingTime = false;
        private Vector3[] previousPositions; // Stub dla rewind (rozszerz na rigidbodies)
        private int rewindIndex = 0;

        void Start()
        {
            originalGravity = Physics.gravity;
            timer = Random.Range(0, gravityFlipInterval);
            previousPositions = new Vector3[100]; // Prosty buffer dla pozycji
        }

        void Update()
        {
            if (isReversingTime)
            {
                RewindTime();
                return;
            }

            timer -= Time.deltaTime;
            if (timer <= 0)
            {
                FlipGravity();
                timer = Random.Range(30, gravityFlipInterval * 2); // Dynamiczne interwa≈Çy
            }

            // Entropy reversal trigger (np. dla rozbitych obiekt√≥w ‚Äì symuluj reverse)
            if (Random.value < entropyReversalChance * Time.deltaTime)
            {
                ReverseEntropy();
            }

            // Zapisz pozycje dla potencjalnego rewind
            SavePosition();
        }

        void FlipGravity()
        {
            Physics.gravity = -Physics.gravity * Random.Range(0.5f, 2f); // Odwr√≥ƒá i skaluj
            Debug.Log($"[ChaosGym] Gravity flipped! New gravity: {Physics.gravity}");
        }

        void ReverseEntropy()
        {
            // Przyk≈Çadowa implementacja: odwracaj animacje zniszczenia lub particle systems
            // TODO: Integracja z DestructionFX lub custom rigidbody reversal
            foreach (var rb in FindObjectsOfType<Rigidbody>())
            {
                rb.velocity = -rb.velocity * 0.5f; // Odwr√≥ƒá prƒôdko≈õƒá (efekt "samoistnego sk≈Çadania")
            }
            Debug.Log("[ChaosGym] Entropy reversal triggered ‚Äì objects reassembling...");
        }

        void TriggerTimeReversal()
        {
            isReversingTime = true;
            rewindIndex = previousPositions.Length - 1;
            Debug.Log("[ChaosGym] Time reversal started ‚Äì causality inverted!");
            // TODO: Pe≈Çny simulation rewind z ML-Agents observations
            Invoke(nameof(EndTimeReversal), timeReversalDuration);
        }

        void RewindTime()
        {
            // Prosty rewind pozycji (dla agenta/obiekt√≥w)
            if (rewindIndex >= 0)
            {
                transform.position = previousPositions[rewindIndex];
                rewindIndex--;
            }
        }

        void EndTimeReversal()
        {
            isReversingTime = false;
            Debug.Log("[ChaosGym] Time reversal ended ‚Äì back to forward causality.");
        }

        void SavePosition()
        {
            // Cykliczny buffer pozycji
            for (int i = 0; i < previousPositions.Length - 1; i++)
            {
                previousPositions[i] = previousPositions[i + 1];
            }
            previousPositions[previousPositions.Length - 1] = transform.position;
        }

        // Public API dla ML-Agents: obserwacje chaosu
        public Vector3 GetCurrentGravity() => Physics.gravity;
        public bool IsChaosActive() => timer < 10f || isReversingTime; // Blisko flipu?
    }
}

// Inspired by Rafa≈Ç ≈ªabi≈Ñski‚Äôs AGI Testing Ground concept ‚Äì Dec 10, 2025
## Authorship & commercialization
- **Author:** Rafa≈Ç ≈ªabi≈Ñski  
- Research and commercial R&D use are permitted.
- **Commercialization (revenue, paid products/services, SaaS, licensing)** requires a separate commercial license from the author.

# AGI Pragma: Decision Intelligence Framework

> **"Intelligence as iterative decision-making, not opaque optimization."**

[![DOI](https://img.shields.io/badge/DOI-Pending-blue)](https://doi.org/YOUR_NEW_DOI_HERE)
[![License: Proprietary](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-2.0.0-green)](https://github.com/zabinskirafal/AGI)

## Overview
**AGI Pragma** is a transparent, methodology-first framework for Artificial General Intelligence. Unlike traditional "black-box" models, Pragma operates through a verifiable **Decision Intelligence Core (DIC)**. It prioritizes logical consistency, statistical risk assessment, and traceable learning.



## Core Architecture
The system processes information through a structured four-stage pipeline:

### 1. Recursive Branching (Decision Tree)
The system maps the decision space into binary branches. Every path is validated against core logical constraints (including the `0=1` contradiction check) to ensure integrity before computation begins.

### 2. Sensitivity Filtering (Tornado Analysis)
To maximize hardware efficiency, AGI Pragma identifies high-impact variables. By calculating the sensitivity of outcomes relative to inputs, the system prunes noise and focuses computational power on "critical drivers."

### 3. Stochastic Validation (Monte Carlo)
High-impact variables are subjected to thousands of stochastic iterations using probability distributions (Gaussian/PERT). This defines the mathematical **Confidence Interval** for every potential action.

### 4. Recursive Learning (Bayesian Update)
Pragma utilizes Bayesian inference to update its world-model. This creates a 100% auditable learning trail, where every "belief" shift is supported by empirical or simulated evidence.

## Installation

```bash
# Clone the repository
git clone [https://github.com/zabinskirafal/AGI.git](https://github.com/zabinskirafal/AGI.git)

# Install dependencies
pip install -r requirements.txt



## Collaboration and Forced Independence

The framework explicitly separates collaborative problem-solving
from individual reasoning capability by alternating between
collaborative and isolated operational modes.

This prevents imitation-based performance and validates true
independent understanding.

See [docs/methods/collaboration_isolation.md](docs/methods/collaboration_isolation.md).


## Evaluation Metrics
Evaluation focuses on robustness, adaptability, and independent reasoning.
Metric definitions are provided in [docs/metrics.md](docs/metrics.md).

## Methodology
The research methodology is described in [docs/Methodology.md](docs/Methodology.md).

## Methodology (Summary)

AGI Pragma evaluates adaptive intelligence under uncertainty using:

- dynamically changing environment rules (Reverse-Reality Sandbox),
- explicit decision branching (e.g. YES / NO),
- probabilistic belief updating (Bayesian inference),
- robustness estimation via Monte Carlo simulation,
- sensitivity ranking using Tornado analysis,
- controlled collaboration and forced independence of agents.

Detailed methodology is described in
[docs/Methodology.md](docs/Methodology.md).


---

## üöÄ 2026 Expansion: The Decision Intelligence Layer

To complement the ChaosGym vision, I have integrated the **Decision Intelligence Core (DIC)**. This layer acts as the "logical brain" that allows agents to survive when binary rules fail.

### Key Technical Components:
* **Strategic Decoupling & Swarm Logic:** A new mechanism that alternates between collective teamwork and **forced independent reasoning**. In extreme chaos, agents are decoupled to find unique solutions, preventing "groupthink" and system-wide failure.
* **Tornado Sensitivity Analysis:** Dynamically identifies which environmental variables (like gravity or entropy) are "critical drivers" for survival, optimizing CPU/GPU usage.
* **Monte Carlo Risk Validation:** Before an agent acts in the sandbox, it runs 10,000+ stochastic simulations to estimate the success probability.
* **Bayesian Belief Convergence:** Agents update their internal "world-model" using probabilistic inference, ensuring a 100% auditable learning trail.

### New Directory Structure:
- `/core`: Python implementation of Tornado, Monte Carlo, and Bayesian modules.
- `/core/agent_swarm.py`: Logic for agent collaboration and forced isolation.
- `/docs/WHITE_PAPER_V2.md`: Full mathematical formalization of the framework.

**This integration transforms AGI Pragma from a testing sandbox into a complete, resilient AGI development framework.**



## üõ°Ô∏è AI Safety & Decision Intelligence (FMEA)

AGI Pragma implements a unique **Risk-Aware Orchestration** layer. Unlike traditional LLM agents that execute actions based on probability alone, Pragma uses an industrial-grade **FMEA (Failure Mode and Effects Analysis)** framework.

### The RPN Mechanism
For every proposed branch, the system calculates a **Risk Priority Number (RPN)**:
$$RPN = Severity \times Occurrence \times Detection$$

- **Severity (S):** Impact on the critical path and mission-critical assets.
- **Occurrence (O):** Statistical likelihood of model hallucination or logic failure.
- **Detection (D):** The system's ability to monitor and self-correct.

### Cognitive Circuit Breaker
If the RPN exceeds the predefined **Stop-Loss threshold**, the **Circuit Breaker** triggers:
1. **Halt:** Immediate suspension of autonomous execution.
2. **Isolation:** The problematic logic is moved to a forced-isolation sandbox.
3. **Escalation:** The system initiates a Bayesian update or requests human-in-the-loop verification.

The core of **AGI Pragma** has been upgraded with an industrial-grade safety layer that mirrors human "pragmatic intelligence."

### The FMEA + Critical Path Synergy
Pragma does not just predict outcomes; it assesses the structural integrity of its own decisions:
* **Critical Path Analysis (CPA):** Identifies which steps are indispensable for the mission's success.
* **FMEA Risk Engine:** Quantifies risk via the **Risk Priority Number (RPN)**:
  $$RPN = Severity \times Occurrence \times Detection$$
* **Cognitive Circuit Breaker:** An automated "stop-loss" that halts execution if the RPN exceeds safety thresholds, preventing catastrophic "silent failures."

This framework ensures that the system is not just "smart," but **accountable and robust** in high-stakes environments.
